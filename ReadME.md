# **ğŸ” Web Research Agent**

A powerful web research assistant that automates online research tasks using AI.

## **âœ¨ Features**

* **Automated Web Search:** ğŸŒ Search across multiple sources, hands-free!
* **Content Extraction & Analysis:** ğŸ§  Extracts and analyzes content for maximum relevance.
* **Information Synthesis:** ğŸ“ Compiles findings into comprehensive reports.
* **News Aggregation:** ğŸ“° Gathers the latest news on your chosen topics.

## **ğŸ› ï¸ Technical Implementation**

* **Backend:** Python with Flask ğŸ
* **AI Models:** Google Gemini 1.5 Flash ğŸ¤–
* **Web Scraping:** BeautifulSoup4 ğŸœ
* **Search API:** SerpAPI ğŸ”
* **Frontend:** HTML, CSS, JavaScript ğŸ¨

## **ğŸ”— Tool Integration**

The agent integrates with the following tools:

1. **Web Search Tool:** Uses SerpAPI to scour the web and deliver relevant search results.
2. **Web Scraper:** Employs BeautifulSoup to extract text and data from websites.
3. **Content Analyzer:** Leverages Google's Gemini model to analyze content relevance.
4. **News Aggregator:** Finds recent news articles on specific topics.

## **ğŸš€ Setup Instructions**

### **Prerequisites**

* Python 3.x
* Git

### **Installation**

1. Clone the repository:
   ```bash
   git clone https://github.com/yourusername/web-research-agent.git
   cd web-research-agent
   ```

2. Create a virtual environment and activate it:
   ```bash
   # For Linux/macOS
   python -m venv venv
   source venv/bin/activate

   # For Windows
   python -m venv venv
   .\venv\Scripts\activate
   ```

3. Install the dependencies:
   ```bash
   pip install -r requirements.txt
   ```

### **Configuration**

1. Create a .env file in the root directory of the project.
2. Add your API keys to the .env file:
   ```
   GEMINI_API_KEY=your_gemini_api_key
   SERPAPI_KEY=your_serpapi_key
   ```

### **Deployment Options**

#### **Vercel Deployment**
This application is optimized for deployment on Vercel:

1. Connect your GitHub repository to Vercel
2. Configure the following settings:
   - Framework Preset: Flask
   - Build Command: `pip install -r requirements.txt`
   - Output Directory: `./`
   - Install Command: `pip install -r requirements.txt`
3. Add your environment variables (GEMINI_API_KEY and SERPAPI_KEY) in the Vercel dashboard
4. Set the Function Execution Timeout to 60 seconds in the Vercel project settings

The application is optimized to work within Vercel's resource limits (0.6 CPU, 1026MB RAM).

## **ğŸ¯ Usage**

1. Start the Flask server:
   ```bash
   python app.py
   ```

2. Open your browser and navigate to http://localhost:8080 (or the port specified by the application).
3. Enter your research query in the input field and click "Research".

## **âš ï¸ Error Handling and Limitations**
### **Current Limitations**

1. **API Dependency:** The application relies on external APIs (SerpAPI and Google Gemini). Availability and usage limits of these services may affect functionality.
2. **Content Extraction:** Web scraping can be unreliable for websites with complex JavaScript rendering or anti-scraping measures.
3. **Processing Time:** Complex queries requiring extensive searching and analysis can take significant time to process.
4. **Concurrent Requests:** The application supports up to 5 concurrent requests on the Vercel deployment.

## **ğŸš€ Deployment**

The application is deployed on Vercel and can be accessed at: [https://web-research-agent.vercel.app/](https://web-research-agent.vercel.app/)

### **Vercel Deployment Specifications**
- **CPU Allocation:** 0.6 CPU
- **Memory:** 1026MB RAM
- **Timeout:** 60 seconds

These improved resources resolve previous limitations when the application was deployed on Render's free tier (0.1 CPU, 512MB RAM, 10-second timeout), allowing:
- Processing of multiple search results before timeout
- Sufficient memory to store and analyze content from multiple websites
- More CPU power for faster content processing and analysis
- Support for more concurrent requests (increased from 3 to 5)

## **ğŸ“œ License**

[MIT License](LICENSE)
